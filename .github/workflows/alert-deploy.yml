# ============================================
# File: .github/workflows/alert-deploy.yml
# Repository: nse-analyzer
# ============================================

name: NSE Hourly Alerts

on:
  # schedule:                     #// cron now in cloudflare via wrangler
    # - cron: "3 5-10 * * 1-5"    #// 10:33‚Äì15:33 IST (Mon‚ÄìFri)
  workflow_dispatch: 

env:
  RUST_LOG: info
  CARGO_TERM_COLOR: always

jobs:
  alert-deploy:
    runs-on: ubuntu-latest
    timeout-minutes: 12  # Kill entire job after 10 minutes

    env:
      ANALYSIS_SUCCESS: "false"
      SUCCESS_COUNT: "0"
      FAILED_COUNT: "0"
      ALERT_COUNT: "0"
      SECURITY_COUNT: "0"
      SECURITIES_WITH_ALERTS: "None"
      IST_TIMESTAMP: ""
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      
    - name: Setup Rust
      uses: dtolnay/rust-toolchain@stable
      with:
        toolchain: stable
        
    - name: Cache Cargo registry
      uses: Swatinem/rust-cache@v2
      with:
        workspaces: backend -> target
        cache-on-failure: true
          
    - name: Build Rust NSE Analyzer
      working-directory: backend
      run: cargo build --release
      
    - name: Run Rust NSE Batch Analysis
      timeout-minutes: 8
      working-directory: backend
      run: |
        export NSE_MODE=batch
        export EXCHANGE=nse
        
        ./target/release/nse-analyzer | tee nse_output.log

        SUCCESS_COUNT=$(grep -oP '‚úì Successful:\s*\K[0-9]+' nse_output.log || echo 0)
        FAILED_COUNT=$(grep -oP '‚úó Failed:\s*\K[0-9]+' nse_output.log || echo 0)

        echo "SUCCESS_COUNT=$SUCCESS_COUNT" >> $GITHUB_ENV
        echo "FAILED_COUNT=$FAILED_COUNT" >> $GITHUB_ENV
        
        if [ -f "batch_rules.json" ]; then
          echo "ANALYSIS_SUCCESS=true" >> $GITHUB_ENV
          
          ALERT_COUNT=$(jq '[.[].alerts | length] | add // 0' batch_rules.json)
          SECURITY_COUNT=$(jq 'length' batch_rules.json)
          
          echo "ALERT_COUNT=$ALERT_COUNT" >> $GITHUB_ENV
          echo "SECURITY_COUNT=$SECURITY_COUNT" >> $GITHUB_ENV
          
          SECURITIES_WITH_ALERTS=$(jq -r '.[].symbol' batch_rules.json | tr '\n' ', ' | sed 's/,$//')
          echo "SECURITIES_WITH_ALERTS=$SECURITIES_WITH_ALERTS" >> $GITHUB_ENV
          
          TABLE_DATA=$(jq -r '
            [.[].alerts[]
             | {
                 type: (
                   if .alert_type == "HUGE_OI_INCREASE" and .option_type == "CE" then
                     "Call_OI_INCREASE"
                   elif .alert_type == "HUGE_OI_INCREASE" and .option_type == "PE" then
                     "Put_OI_INCREASE"
                   elif .alert_type == "HUGE_OI_DECREASE" and .option_type == "CE" then
                     "Call_OI_DECREASE"
                   elif .alert_type == "HUGE_OI_DECREASE" and .option_type == "PE" then
                     "Put_OI_DECREASE"
                   else
                     .alert_type
                   end
                 ),
                 symbol: .symbol
               }
            ]
            | group_by(.type)
            | map({
                alert_type: .[0].type,
                securities: [.[].symbol] | unique | join(","),
                count: length
              })
            | sort_by(.count) | reverse
            | .[]
            | "\(.alert_type)|\(.count)|\(.securities)"
          ' batch_rules.json)

          {
            echo "ALERT_TABLE_DATA<<EOF"
            echo "$TABLE_DATA"
            echo "EOF"
          } >> "$GITHUB_ENV"
          
        else
          echo "ANALYSIS_SUCCESS=false" >> $GITHUB_ENV
          echo "ALERT_COUNT=0" >> $GITHUB_ENV
          echo "SECURITY_COUNT=0" >> $GITHUB_ENV
          echo "SECURITIES_WITH_ALERTS=None" >> $GITHUB_ENV
          echo "ALERT_TABLE_DATA=" >> $GITHUB_ENV
        fi

    - name: Archive analysis results
      if: ${{ env.ANALYSIS_SUCCESS == 'true' }}
      uses: actions/upload-artifact@v4
      with:
        name: nse-batch-rules-${{ github.run_number }}
        path: backend/batch_rules.json
        retention-days: 10
    
    # ============================================
    # NEW: Upload to Vercel Blob & Trigger Deploy
    # ============================================
    - name: Setup Node.js
      if: ${{ env.ANALYSIS_SUCCESS == 'true' }}
      uses: actions/setup-node@v4
      with:
        node-version: '20'
    
    - name: Install Vercel CLI and Blob SDK
      if: ${{ env.ANALYSIS_SUCCESS == 'true' }}
      run: |
        npm install -g vercel@latest
        npm install @vercel/blob
    
    - name: Upload batch_rules.json and processed_data to Vercel Blob
      if: ${{ env.ANALYSIS_SUCCESS == 'true' }}
      working-directory: backend
      env:
        BLOB_READ_WRITE_TOKEN: ${{ secrets.BLOB_READ_WRITE_TOKEN }}
      run: |
        cat > upload-blob.mjs << 'EOF'
        import { put, list, del } from '@vercel/blob';
        import { readFileSync, readdirSync, appendFileSync } from 'fs';
        import { join } from 'path';
        
        // Step 1: Clean up old processed_data files
        console.log('üßπ Cleaning up old processed_data files...');
        const oldFiles = await list({
          prefix: 'data/processed_data/',
          token: process.env.BLOB_READ_WRITE_TOKEN,
        });
        
        let deletedCount = 0;
        for (const file of oldFiles.blobs) {
          await del(file.url, { token: process.env.BLOB_READ_WRITE_TOKEN });
          deletedCount++;
        }
        console.log(`‚úì Deleted ${deletedCount} old files\n`);
        
        // Step 2: Upload batch_rules.json
        const batchRulesContent = readFileSync('batch_rules.json', 'utf-8');
        const batchRulesBlob = await put('data/batch_rules.json', batchRulesContent, {
          access: 'public',
          token: process.env.BLOB_READ_WRITE_TOKEN,
          addRandomSuffix: false,
          allowOverwrite: true,
        });
        
        console.log('‚úÖ Uploaded batch_rules.json to Vercel Blob');
        console.log('URL:', batchRulesBlob.url);
        console.log('Pathname:', batchRulesBlob.pathname);
        
        // Step 3: Upload all files from processed_data directory
        const processedDataDir = 'processed_data';
        const files = readdirSync(processedDataDir);
        
        console.log(`\nüìÅ Uploading ${files.length} files from processed_data/...`);
        
        let uploadedCount = 0;
        const uploadedFiles = [];
        
        for (const file of files) {
          if (file.endsWith('.json')) {
            const filePath = join(processedDataDir, file);
            const fileContent = readFileSync(filePath, 'utf-8');
            
            const blob = await put(`data/processed_data/${file}`, fileContent, {
              access: 'public',
              token: process.env.BLOB_READ_WRITE_TOKEN,
              addRandomSuffix: false,
            });
            
            uploadedCount++;
            uploadedFiles.push(file);
            console.log(`‚úì Uploaded ${file}`);
          }
        }
        
        console.log(`\n‚úÖ Successfully uploaded ${uploadedCount} ticker files to Vercel Blob`);
        console.log('Files:', uploadedFiles.join(', '));
        
        // Save info to GitHub environment
        appendFileSync(process.env.GITHUB_ENV, `BLOB_BATCH_RULES_URL=${batchRulesBlob.url}\n`);
        appendFileSync(process.env.GITHUB_ENV, `BLOB_TICKER_COUNT=${uploadedCount}\n`);
        appendFileSync(process.env.GITHUB_ENV, `BLOB_DELETED_COUNT=${deletedCount}\n`);
        EOF
        
        node upload-blob.mjs
        
    - name: Trigger Vercel Deployment
      if: ${{ env.ANALYSIS_SUCCESS == 'true' }}
      run: |
        # Trigger deployment using Vercel Deploy Hook
        curl -X POST "${{ secrets.VERCEL_DEPLOY_HOOK }}"
        echo "‚úÖ Vercel deployment triggered"
    
    # Alternative: Use Vercel CLI to deploy (if you prefer)
    # - name: Trigger Vercel Deployment via CLI
    #   if: ${{ env.ANALYSIS_SUCCESS == 'true' }}
    #   run: |
    #     vercel deploy --prod --token=${{ secrets.VERCEL_TOKEN }} --yes
    
    # ============================================
    # END: Vercel Blob Upload
    # ============================================
        
    - name: Format Alert Table
      id: format-table
      if: failure()
      run: |
        if [ "$ANALYSIS_SUCCESS" = "true" ] && [ -n "$ALERT_TABLE_DATA" ]; then
          html_table='<table border="1" cellpadding="4" cellspacing="0" style="border-collapse:collapse;font-family:monospace;font-size:12px;">
            <tr>
              <th align="left">Alert Type</th>
              <th align="right">Alert Count</th>
              <th align="left">Securities</th>
            </tr>'

          while IFS='|' read -r alert_type count securities; do
            [ -z "$alert_type" ] && continue
            esc_type=$(printf '%s' "$alert_type" | sed 's/&/\&amp;/g; s/</\&lt;/g; s/>/\&gt;/g')
            esc_secs=$(printf '%s' "$securities" | sed 's/&/\&amp;/g; s/</\&lt;/g; s/>/\&gt;/g')
            html_table="${html_table}
            <tr>
              <td>${esc_type}</td>
              <td align=\"right\">${count}</td>
              <td>${esc_secs}</td>
            </tr>"
          done <<< "$ALERT_TABLE_DATA"

          html_table="${html_table}</table>"
          formatted_output="$html_table"
        else
          if [ "$ANALYSIS_SUCCESS" = "true" ]; then
            formatted_output="<p>No alerts found - all securities clean!</p>"
          else
            formatted_output="<p>Analysis failed or timed out - no data available.</p>"
          fi
        fi

        {
          echo "formatted_table<<EOF"
          echo "$formatted_output"
          echo "EOF"
        } >> "$GITHUB_OUTPUT"

    - name: Generate IST Timestamp
      if: failure()
      run: |
        IST_TIME=$(TZ="Asia/Kolkata" date +"%d %b %y %H:%M")
        echo "IST_TIMESTAMP=$IST_TIME" >> $GITHUB_ENV
        
    - name: Send email notification
      if: always()
      uses: dawidd6/action-send-mail@v3
      with:
        server_address: smtp.gmail.com
        server_port: 587
        username: ${{ secrets.GMAIL_USERNAME }}
        password: ${{ secrets.GMAIL_PASSWORD }}
        subject: "NSE Analysis Report - ${{ env.IST_TIMESTAMP }} (${{ env.ANALYSIS_SUCCESS == 'true' && 'SUCCESS' || 'FAILED' }})"
        to: ${{ secrets.EMAIL_RECIPIENT }}
        from: ${{ secrets.GMAIL_USERNAME }}
        html_body: |
            <html>
              <body style="font-family: Arial, sans-serif; font-size: 14px;">
                <h2>NSE Daily Analysis Report</h2>
                <hr />
                <br>
                <h3>üßÆ Processing Stats</h3>
                <ul>
                  <li><b>‚úì Successful:</b> ${{ env.SUCCESS_COUNT || '0' }}</li>
                  <li><b>‚úó Failed:</b> ${{ env.FAILED_COUNT || '0' }}</li>
                </ul>

                <h3>üìä Summary</h3>
                <ul>
                  <li><b>Securities with alerts:</b> ${{ env.SECURITY_COUNT || '0' }}</li>
                  <li><b>Total alerts generated:</b> ${{ env.ALERT_COUNT || '0' }}</li>
                  <li><b>Status:</b> ${{ env.ANALYSIS_SUCCESS == 'true' && '‚úÖ Completed Successfully' || '‚ùå Failed/Timeout' }}</li>
                </ul>

                <h3>üè¢ Securities with Alerts</h3>
                <p>${{ env.SECURITIES_WITH_ALERTS || 'None' }}</p>

                <h3>üìà Alert Breakdown</h3>
                ${{ steps.format-table.outputs.formatted_table }}

                ${{ env.ANALYSIS_SUCCESS == 'true' && '<h3>üöÄ Deployment Status</h3><p>‚úÖ batch_rules.json has been pushed to Vercel Blob - Deployment triggered automatically</p>' || '' }}

                ${{ env.ANALYSIS_SUCCESS != 'true' && '<h3>‚ÑπÔ∏è Troubleshooting (if failed)</h3><ul><li>NSE API timeout (90 second limit)</li><li>Network connectivity issues</li><li>NSE server problems</li><li>Market hours / trading session status</li></ul>' || '' }}

                <h3>üîó Additional Info</h3>
                <ul>
                  <li><b>Run ID:</b> ${{ github.run_number }}</li>
                  <li><b>Repository:</b> ${{ github.repository }}</li>
                  <li><b>Full artifacts:</b> <a href="${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}">Open in GitHub</a></li>
                  <li><b>Generated at:</b> ${{ env.IST_TIMESTAMP }}</li>
                </ul>
              </body>
            </html>
        attachments: backend/batch_rules.json

    - name: Notification on failure
      if: failure()
      uses: dawidd6/action-send-mail@v3
      with:
        server_address: smtp.gmail.com
        server_port: 587
        username: ${{ secrets.GMAIL_USERNAME }}
        password: ${{ secrets.GMAIL_PASSWORD }}
        subject: "üö® NSE Analysis FAILED - ${{ env.IST_TIMESTAMP }}"
        to: ${{ secrets.EMAIL_RECIPIENT }},${{ secrets.EMAIL_RECIPIENT_2 }}
        from: ${{ secrets.GMAIL_USERNAME }}
        body: |
          ‚ö†Ô∏è NSE Daily Analysis Failed
          
          Run ID: ${{ github.run_number }}
          Repository: ${{ github.repository }}
          Generated at: ${{ env.IST_TIMESTAMP }}
          
          Please check the logs at:
          ${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}
          
          Error details may be available in the workflow logs.